{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4c7312",
   "metadata": {},
   "source": [
    "## Demo embedding extraction\n",
    "\n",
    "This notebook shows how to use the embedding extraction module for generating numerical representation using the pre-trained models.\n",
    "\n",
    "The following family of pre-trained models is available for testing\n",
    "\n",
    "- Prot5Based\n",
    "- ESMBasedEmbedding\n",
    "- Ankh2BasedEmbedding\n",
    "- BertBasedMebedding\n",
    "- MistralBasedEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67f933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08911398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6a1a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a8709",
   "metadata": {},
   "source": [
    "- Loading modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6456dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding_extraction.prot5_based import Prot5Based\n",
    "from embedding_extraction.esm_based import ESMBasedEmbedding\n",
    "from embedding_extraction.bert_based import BertBasedMebedding\n",
    "from embedding_extraction.mistral_based import MistralBasedEmbedding\n",
    "from dimensionality_reductions.non_linear_reductions import NonLinearReductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eaa816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeca857",
   "metadata": {},
   "source": [
    "- Read AMP dataset and select only 10 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8143fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"../../data/antiviral_homology_90.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e98227d",
   "metadata": {},
   "source": [
    "### ProT5 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa29dc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n",
      "Loading model/tokenizer\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m prot5_based \u001b[38;5;241m=\u001b[39m Prot5Based(\n\u001b[1;32m      5\u001b[0m     name_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdf_to_prot5,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     columns_ignore\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model/tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mprot5_based\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m df_embedding \u001b[38;5;241m=\u001b[39m prot5_based\u001b[38;5;241m.\u001b[39membedding_process(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "File \u001b[0;32m~/Escritorio/Half_Life/HL/src/models/../../utils/embedding_extraction/prot5_based.py:25\u001b[0m, in \u001b[0;36mProt5Based.load_model_tokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_model_tokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m T5Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_model, do_lower_case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mT5EncoderModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname_model\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/micromamba/envs/ML_Class/lib/python3.9/site-packages/transformers/modeling_utils.py:309\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/micromamba/envs/ML_Class/lib/python3.9/site-packages/transformers/modeling_utils.py:4573\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4564\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4566\u001b[0m     (\n\u001b[1;32m   4567\u001b[0m         model,\n\u001b[1;32m   4568\u001b[0m         missing_keys,\n\u001b[1;32m   4569\u001b[0m         unexpected_keys,\n\u001b[1;32m   4570\u001b[0m         mismatched_keys,\n\u001b[1;32m   4571\u001b[0m         offload_index,\n\u001b[1;32m   4572\u001b[0m         error_msgs,\n\u001b[0;32m-> 4573\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4579\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4582\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4591\u001b[0m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[1;32m   4592\u001b[0m model\u001b[38;5;241m.\u001b[39m_tp_size \u001b[38;5;241m=\u001b[39m tp_size\n",
      "File \u001b[0;32m~/micromamba/envs/ML_Class/lib/python3.9/site-packages/transformers/modeling_utils.py:4832\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4829\u001b[0m     original_checkpoint_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(state_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   4830\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4831\u001b[0m     original_checkpoint_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m-> 4832\u001b[0m         \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m   4833\u001b[0m     )\n\u001b[1;32m   4835\u001b[0m \u001b[38;5;66;03m# Check if we are in a special state, i.e. loading from a state dict coming from a different architecture\u001b[39;00m\n\u001b[1;32m   4836\u001b[0m prefix \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbase_model_prefix\n",
      "File \u001b[0;32m~/micromamba/envs/ML_Class/lib/python3.9/site-packages/transformers/modeling_utils.py:553\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# Fallback to torch.load (if weights_only was explicitly False, do not check safety as this is known to be unsafe)\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m--> 553\u001b[0m     \u001b[43mcheck_torch_load_is_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m map_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/ML_Class/lib/python3.9/site-packages/transformers/utils/import_utils.py:1417\u001b[0m, in \u001b[0;36mcheck_torch_load_is_safe\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_torch_load_is_safe\u001b[39m():\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_greater_or_equal(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.6\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1417\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1418\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDue to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1419\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1420\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen loading files with safetensors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1421\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1422\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434"
     ]
    }
   ],
   "source": [
    "df_to_prot5 = df_data.copy()\n",
    "df_to_prot5[\"sequence\"] = df_to_prot5[\"sequence\"].apply(lambda x: \" \".join(x)) # this process is necessary for the application of the pre-trained model\n",
    "\n",
    "prot5_based = Prot5Based(\n",
    "    name_device=\"cuda\",\n",
    "    dataset=df_to_prot5,\n",
    "    name_model=\"Rostlab/ProstT5\",\n",
    "    name_tokenizer=\"Rostlab/ProstT5\",\n",
    "    column_seq=\"sequence\",\n",
    "    columns_ignore=[\"label\"],\n",
    ")\n",
    "\n",
    "print(\"Loading model/tokenizer\")\n",
    "prot5_based.load_model_tokenizer()\n",
    "\n",
    "print(\"Generating embedding\")\n",
    "df_embedding = prot5_based.embedding_process(batch_size=64)\n",
    "\n",
    "prot5_based.cleaning_memory()\n",
    "print(\"Process finished\")\n",
    "\n",
    "df_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab239559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = df_embedding.drop(columns=[\"label\"])\n",
    "nonlinear_instance = NonLinearReductions(dataset=df_values)\n",
    "\n",
    "transform_values_umap = nonlinear_instance.applyUMAP()\n",
    "transform_values_umap[\"label\"] = df_embedding[\"label\"].values\n",
    "\n",
    "sns.scatterplot(data=transform_values_umap, x=\"p_1\", y=\"p_2\", hue=\"label\", palette=\"Set2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf53300",
   "metadata": {},
   "source": [
    "### ESM evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ec862",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_based = ESMBasedEmbedding(\n",
    "    name_device=\"cuda\",\n",
    "    dataset=df_data,\n",
    "    name_model=\"facebook/esm2_t6_8M_UR50D\",\n",
    "    name_tokenizer=\"facebook/esm2_t6_8M_UR50D\",\n",
    "    column_seq=\"sequence\",\n",
    "    columns_ignore=[\"label\"],\n",
    ")\n",
    "\n",
    "print(\"Loading model/tokenizer\")\n",
    "esm_based.load_model_tokenizer()\n",
    "\n",
    "print(\"Generating embedding\")\n",
    "df_embedding = esm_based.embedding_process(batch_size=64)\n",
    "\n",
    "esm_based.cleaning_memory()\n",
    "print(\"Process finished\")\n",
    "\n",
    "df_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = df_embedding.drop(columns=[\"label\"])\n",
    "nonlinear_instance = NonLinearReductions(dataset=df_values)\n",
    "\n",
    "transform_values_umap = nonlinear_instance.applyUMAP()\n",
    "transform_values_umap[\"label\"] = df_embedding[\"label\"].values\n",
    "\n",
    "sns.scatterplot(data=transform_values_umap, x=\"p_1\", y=\"p_2\", hue=\"label\", palette=\"Set2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8ab71",
   "metadata": {},
   "source": [
    "### Bert evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bcc17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_bert = df_data.copy()\n",
    "df_to_bert[\"sequence\"] = df_to_bert[\"sequence\"].apply(lambda x: \" \".join(x)) # this process is necessary for the application of the pre-trained model\n",
    "\n",
    "bert_based = BertBasedMebedding(\n",
    "    name_device=\"cuda\",\n",
    "    dataset=df_to_bert,\n",
    "    name_model=\"Rostlab/prot_bert_bfd_ss3\",\n",
    "    name_tokenizer=\"Rostlab/prot_bert_bfd_ss3\",\n",
    "    column_seq=\"sequence\",\n",
    "    columns_ignore=[\"label\"],\n",
    ")\n",
    "\n",
    "print(\"Loading model/tokenizer\")\n",
    "bert_based.load_model_tokenizer()\n",
    "\n",
    "print(\"Generating embedding\")\n",
    "df_embedding = bert_based.embedding_process(batch_size=64)\n",
    "\n",
    "bert_based.cleaning_memory()\n",
    "print(\"Process finished\")\n",
    "\n",
    "df_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = df_embedding.drop(columns=[\"label\"])\n",
    "nonlinear_instance = NonLinearReductions(dataset=df_values)\n",
    "\n",
    "transform_values_umap = nonlinear_instance.applyUMAP()\n",
    "transform_values_umap[\"label\"] = df_embedding[\"label\"].values\n",
    "\n",
    "sns.scatterplot(data=transform_values_umap, x=\"p_1\", y=\"p_2\", hue=\"label\", palette=\"Set2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
